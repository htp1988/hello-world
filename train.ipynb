{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccca78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import get_themes\n",
    "import jupyterthemes as jt\n",
    "from jupyterthemes.stylefx import set_nb_theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ceae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_nb_theme(\"chesterish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c16eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% ! important; }<style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0e9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xml_tree(element, indent=' '):\n",
    "    if isinstance(element, dict):\n",
    "        for key, value in element.items():\n",
    "            if isinstance(value, (dict, list)):\n",
    "                print(f\"{indent}{key}:\")\n",
    "                print_xml_tree(value, indent + \"  \")\n",
    "            else:\n",
    "                print(f\"{indent}{key}: {value}\")\n",
    "\n",
    "    else:\n",
    "        print(f'{indent}{element}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbf8ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " annotation:\n",
      "   folder: OXIIIT\n",
      "   filename: Abyssinian_100.jpg\n",
      "   source:\n",
      "     database: OXFORD-IIIT Pet Dataset\n",
      "     annotation: OXIIIT\n",
      "     image: flickr\n",
      "   size:\n",
      "     width: 394\n",
      "     height: 500\n",
      "     depth: 3\n",
      "   segmented: 0\n",
      "   object:\n",
      "     name: cat\n",
      "     pose: Frontal\n",
      "     truncated: 0\n",
      "     occluded: 0\n",
      "     bndbox:\n",
      "       xmin: 151\n",
      "       ymin: 71\n",
      "       xmax: 335\n",
      "       ymax: 267\n",
      "     difficult: 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import json\n",
    "import os\n",
    "\n",
    "doc = xmltodict.parse(open('./Oxford_Pet_Dataset/annotations/xmls/Abyssinian_100.xml').read())\n",
    "\n",
    "print_xml_tree(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46960b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bbox(img):\n",
    "    rows = np.any(img == 1, axis=1)\n",
    "    cols = np.any(img == 1, axis=0)\n",
    "    ymin, ymax = np.where(rows)[0][[0, -1]]\n",
    "    xmin, xmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return max(xmin - 15, 0), min(xmax + 15, img.shape[1]), max(ymin - 15, 0), min(ymax + 15, img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6602c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask\n",
    "\n",
    "def generateVOC2Json(rootDir, xmlFiles):\n",
    "    attrDict = {}\n",
    "    attrDict['categories'] = [\n",
    "        {'supercategory':'none', 'id':0, 'name':'cat'},\n",
    "        {'supercategory':'none', 'id':1, 'name':'dog'}\n",
    "    ]\n",
    "    \n",
    "    images = []\n",
    "    annotations = []\n",
    "    annotation_id = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(rootDir):\n",
    "        image_id = 0\n",
    "        for file in xmlFiles:\n",
    "            image_id += 1\n",
    "            if file in files:\n",
    "                try:\n",
    "                    path = root + file\n",
    "                    image = {}\n",
    "                    doc = xmltodict.parse(open(path).read())\n",
    "                    image['file_name'] = doc['annotation']['filename']\n",
    "                    image['height'] = int(doc['annotation']['size']['height'])\n",
    "                    image['width'] = int(doc['annotation']['size']['width'])\n",
    "                    image['sem_seg_file_name'] = root[:-5] + 'trimaps/' + file[:-4] + '.png'\n",
    "                    image['id'] = image_id\n",
    "                    images.append(image)\n",
    "\n",
    "                    if 'object' in doc['annotation']:\n",
    "                        obj = doc['annotation']['object']\n",
    "                        for value in attrDict['categories']:\n",
    "                            annotation = {}\n",
    "                            if obj['name'] == value['name']:\n",
    "                                annotation['iscrowd'] = 0\n",
    "                                annotation['image_id'] = image_id\n",
    "                                annotation['category_id'] = value['id']\n",
    "                                annotation['ignore'] = 0\n",
    "                                annotation['id'] = annotation_id\n",
    "                                \n",
    "                                image_mask = cv2.imread(image['sem_seg_file_name'])\n",
    "                                xmin, xmax, ymin, ymax = mask_to_bbox(image_mask[:, :, 0])\n",
    "                                \n",
    "                                image_mask = np.where(image_mask==3, 1, image_mask)\n",
    "                                image_mask = np.where(image_mask==2, 0, image_mask)\n",
    "                                image_mask = image_mask.astype('uint8')\n",
    "\n",
    "                                segmask = mask.encode(np.asarray(image_mask, order='F'))\n",
    "                                for seg in segmask:\n",
    "                                    seg['counts'] = seg['counts'].decode('utf-8')\n",
    "                                \n",
    "                                x1 = int(xmin)\n",
    "                                y1 = int(ymin)\n",
    "                                x2 = int(xmax - x1)\n",
    "                                y2 = int(ymax - y1)\n",
    "\n",
    "                                annotation['bbox'] = [x1, y1, x2, y2]\n",
    "                                annotation['area'] = float(x2 * y2)\n",
    "                                annotation['segmentation'] = segmask[0]\n",
    "                                \n",
    "                                annotation_id += 1\n",
    "                                annotations.append(annotation)\n",
    "                        \n",
    "                    else:\n",
    "                        print(f'File: {file} does not have any object')    \n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                print(f'File {file} not found')\n",
    "        \n",
    "    attrDict['images'] = images\n",
    "    attrDict['annotations'] = annotations\n",
    "    jsonString = json.dumps(attrDict)\n",
    "        \n",
    "    return jsonString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9028d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Abyssinian_104.xml not found\n",
      "File Bengal_111.xml not found\n",
      "File samoyed_10.xml not found\n",
      "File Bengal_175.xml not found\n",
      "File Egyptian_Mau_14.xml not found\n",
      "File Egyptian_Mau_156.xml not found\n",
      "File Egyptian_Mau_186.xml not found\n",
      "File Ragdoll_199.xml not found\n",
      "File saint_bernard_15.xml not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "rootDir = './Oxford_Pet_Dataset/annotations/xmls/'\n",
    "trainFile = './Oxford_Pet_Dataset/annotations/trainval.txt'\n",
    "xmlFiles = []\n",
    "\n",
    "with open(trainFile, 'r') as f:\n",
    "    for line in f:\n",
    "        fileName = line.strip().split()[0]\n",
    "        xmlFiles.append(fileName + '.xml')\n",
    "\n",
    "train_xmlFiles = generateVOC2Json(rootDir, xmlFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ad7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Oxford_Pet_Dataset/annotations/train_segment.json', 'w') as f:\n",
    "    f.write(train_xmlFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23187dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "train = 'train'\n",
    "test = 'test'\n",
    "\n",
    "image_root = './Oxford_Pet_Dataset/images'\n",
    "train_json = './Oxford_Pet_Dataset/annotations/train_segment.json'\n",
    "\n",
    "register_coco_instances(train, {}, train_json, image_root)\n",
    "metadata = MetadataCatalog.get(train)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('C:/Users/phuc2/anaconda3/envs/cuda_env/Lib/site-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.DATASETS.TRAIN = (train,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 4  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "cfg.OUTPUT_DIR = './Oxford_Pet_Dataset/'\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098d74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "train = 'test'\n",
    "\n",
    "image_root = './Oxford_Pet_Dataset/images'\n",
    "train_json = './Oxford_Pet_Dataset/annotations/train_segment.json'\n",
    "\n",
    "register_coco_instances(train, {}, train_json, image_root)\n",
    "metadata = MetadataCatalog.get(train)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('C:/Users/phuc2/anaconda3/envs/cuda_env/Lib/site-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 4  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n",
    "cfg.OUTPUT_DIR = './Oxford_Pet_Dataset/'\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.MODEL.WEIGHTS = cfg.OUTPUT_DIR + 'model_0001999.pth'\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "dicts = DatasetCatalog.get(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for d in random.sample(dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(vis.get_image())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lu = cv2.imread(\"C:/Users/phuc2/Downloads/IMG_2322.jpg\")\n",
    "lu = cv2.resize(lu, (cfg.INPUT.MIN_SIZE_TRAIN[0], cfg.INPUT.MIN_SIZE_TRAIN[1]))\n",
    "\n",
    "outputs_lu = predictor(lu)\n",
    "visualizer_lu = Visualizer(lu[:,:,::-1], metadata)\n",
    "vis_lu = visualizer_lu.draw_instance_predictions(outputs_lu['instances'].to('cpu'))\n",
    "\n",
    "plt.imshow(vis_lu.get_image())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6fb59e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('coco_2017_val',)\n",
      "  TRAIN: ('coco_2017_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: bitmask\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\n",
      "    FED_LOSS_NUM_CLASSES: 50\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "    USE_FED_LOSS: False\n",
      "    USE_SIGMOID_CE: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 4\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 2\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.8\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    CONV_DIMS: [-1]\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: ./Oxford_Pet_Dataset/model_0001999.pth\n",
      "OUTPUT_DIR: ./Oxford_Pet_Dataset/\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.02\n",
      "  BASE_LR_END: 0.0\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 16\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 90000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  NUM_DECAYS: 3\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  RESCALE_INTERVAL: False\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: None\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "cuda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
